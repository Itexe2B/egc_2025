{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as python_random\n",
    "\n",
    "import imageio as iio\n",
    "import json\n",
    "\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "python_random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelOut(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    CancelOut Layer\n",
    "    '''\n",
    "    def __init__(self, activation='sigmoid', cancelout_loss=True, lambda_1=0.002, lambda_2=0.001):\n",
    "        super(CancelOut, self).__init__()\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.cancelout_loss = cancelout_loss\n",
    "        \n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = tf.keras.activations.sigmoid\n",
    "        elif activation == 'softmax':\n",
    "            self.activation = tf.keras.activations.softmax\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=tf.keras.initializers.Constant(1),\n",
    "            trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.cancelout_loss:\n",
    "            self.add_loss(self.lambda_1 * tf.norm(self.w, ord=1) + self.lambda_2 * tf.norm(self.w, ord=2))\n",
    "        return tf.math.multiply(inputs, self.activation(self.w))\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(CancelOut, self).get_config()\n",
    "        config.update({\n",
    "            \"activation\": self.activation,\n",
    "            \"lambda_1\": self.lambda_1,\n",
    "            \"lambda_2\": self.lambda_2,\n",
    "            \"cancelout_loss\": self.cancelout_loss\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelTCN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, window, feature_size):\n",
    "        super(MyModelTCN, self).__init__()\n",
    "\n",
    "        # Feature Selection\n",
    "        self.fs = CancelOut(activation='sigmoid', cancelout_loss=True, lambda_1=0.002, lambda_2=0.001)\n",
    "        self.reshape_lstm = tf.keras.layers.Reshape((window, feature_size))\n",
    "\n",
    "        # Part for extract topographie\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (3, 3), strides=2, activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(8, (3, 3), strides=2, activation='relu')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')\n",
    "        self.pool = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense_cnn = tf.keras.layers.Dense(64, activation='relu', name='topo_dense')\n",
    "\n",
    "        # Part for extract features\n",
    "        self.tcn = TCN(64, return_sequences=True)\n",
    "        self.tcn2 = TCN(64, return_sequences=False)\n",
    "        self.dense = tf.keras.layers.Dense(128, activation='relu')\n",
    "\n",
    "        # Post Merging\n",
    "        self.dense_pm = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dense_pm1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense_pm2 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_pm3 = tf.keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "    def call(self, x):\n",
    "        '''\n",
    "          x = (topographie data 2D, Features LSTM sized)\n",
    "        '''\n",
    "        topo, features = x\n",
    "        # Extract topographie\n",
    "        t = self.conv1(topo)\n",
    "        t = self.pool(t)\n",
    "        t = self.conv2(t)\n",
    "        t = self.pool(t)\n",
    "        t = self.conv3(t)\n",
    "        t = self.pool(t)\n",
    "        t = self.flatten(t)\n",
    "        t = self.dense_cnn(t)\n",
    "\n",
    "        # Extract features\n",
    "        # f = self.flat_lstm(features)\n",
    "        # f = self.fs(f)\n",
    "        # f = self.reshape_lstm(f)\n",
    "        f = self.flatten(features)\n",
    "        f = self.fs(f)\n",
    "        f = self.reshape_lstm(f)\n",
    "        f = self.tcn(f)\n",
    "        f = self.tcn2(f)\n",
    "        f = self.dense(f)\n",
    "\n",
    "        # Merging\n",
    "        o = tf.keras.layers.concatenate([t, f])\n",
    "\n",
    "        # Post Merging\n",
    "        o = self.dense_pm(o)\n",
    "        o = self.dense_pm1(o)\n",
    "        o = self.dense_pm2(o)\n",
    "        o = self.dense_pm3(o)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelTCNNotHybrid(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, window, feature_size):\n",
    "        super(MyModelTCNNotHybrid, self).__init__()\n",
    "\n",
    "        # Feature Selection\n",
    "        self.fs = CancelOut(activation='sigmoid', cancelout_loss=True, lambda_1=0.002, lambda_2=0.001)\n",
    "        self.reshape_lstm = tf.keras.layers.Reshape((window, feature_size))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        # Part for extract features\n",
    "        self.tcn = TCN(64, return_sequences=True)\n",
    "        self.tcn2 = TCN(64, return_sequences=False)\n",
    "        self.dense = tf.keras.layers.Dense(128, activation='relu')\n",
    "\n",
    "        # Post Merging\n",
    "        self.dense_pm = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dense_pm1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense_pm2 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_pm3 = tf.keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "    def call(self, x):\n",
    "        # Extract features\n",
    "        # f = self.flat_lstm(features)\n",
    "        # f = self.fs(f)\n",
    "        # f = self.reshape_lstm(f)\n",
    "        f = self.flatten(x)\n",
    "        f = self.fs(f)\n",
    "        f = self.reshape_lstm(f)\n",
    "        f = self.tcn(f)\n",
    "        f = self.tcn2(f)\n",
    "        f = self.dense(f)\n",
    "\n",
    "        # Post Merging\n",
    "        f = self.dense_pm(f)\n",
    "        f = self.dense_pm1(f)\n",
    "        f = self.dense_pm2(f)\n",
    "        f = self.dense_pm3(f)\n",
    "\n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, img, x_data, y_data, batch_size):\n",
    "        self.img = img\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x_data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x_data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y_data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_img = np.repeat(np.expand_dims(self.img, axis=0), len(batch_x), axis=0)\n",
    "        return (batch_img, batch_x), batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec Topographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_fenetre = 18\n",
    "horizon = 24\n",
    "ville = 'ajaccio'\n",
    "image = '110'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_577640/2944221117.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = iio.imread(f\"img/{ville}/{image}.jpg\").astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model builded\n"
     ]
    }
   ],
   "source": [
    "FEATURES = ['u100', 'v100', 'u10', 'v10', 't2m', 'i10fg', 'index_hours', 'index_days', 'sp', 'msl', 'd2m']\n",
    "TARGET = 'A10'\n",
    "\n",
    "img = iio.imread(f\"img/{ville}/{image}.jpg\").astype(np.float32)\n",
    "img = tf.convert_to_tensor(img)\n",
    "\n",
    "df_test = pd.read_csv(f\"data/test_{ville}.csv\")\n",
    "\n",
    "df_test_features = df_test[FEATURES].to_numpy()\n",
    "df_test_target = df_test[[TARGET]].to_numpy()\n",
    "\n",
    "def creer_sequences(features, target, taille_fenetre, horizon):\n",
    "      x, y = [], []\n",
    "      for i in range(len(features) - taille_fenetre - horizon + 1):\n",
    "        x.append(features[i:(i + taille_fenetre)])\n",
    "        y.append(target[i + taille_fenetre + horizon - 1])\n",
    "      return np.array(x), np.array(y)\n",
    "\n",
    "x_test, y_test = creer_sequences(df_test_features, df_test_target, taille_fenetre, horizon)\n",
    "batch_size = 32\n",
    "test_generator = DataGenerator(img, x_test, y_test, batch_size)\n",
    "\n",
    "model = MyModelTCN(taille_fenetre, len(FEATURES))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae', tf.keras.metrics.RootMeanSquaredError()])\n",
    "#build\n",
    "model((tf.random.uniform((batch_size, int(image), int(image), 3)) , tf.random.uniform((batch_size, taille_fenetre, len(FEATURES)))))\n",
    "print(\"model builded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 139 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 12ms/step - loss: 3.9443 - mse: 3.9319 - mape: 81.4344 - mae: 1.3828 - root_mean_squared_error: 1.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.944338798522949,\n",
       " 3.9319393634796143,\n",
       " 81.43444061279297,\n",
       " 1.3827601671218872,\n",
       " 1.9829118251800537]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"model_trained/{ville}/checkpoint_tcn_A10_{ville}_amplitude_zoom_{image}_{horizon}h.weights.h5\")\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sans Topographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_fenetre = 18\n",
    "horizon = 24\n",
    "ville = 'bastia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model builded\n"
     ]
    }
   ],
   "source": [
    "FEATURES = ['u100', 'v100', 'u10', 'v10', 't2m', 'i10fg', 'index_hours', 'index_days', 'sp', 'msl', 'd2m']\n",
    "TARGET = 'A10'\n",
    "\n",
    "df_test = pd.read_csv(f\"data/test_{ville}.csv\")\n",
    "\n",
    "df_test_features = df_test[FEATURES].to_numpy()\n",
    "df_test_target = df_test[[TARGET]].to_numpy()\n",
    "\n",
    "def creer_sequences(features, target, taille_fenetre, horizon):\n",
    "      x, y = [], []\n",
    "      for i in range(len(features) - taille_fenetre - horizon + 1):\n",
    "        x.append(features[i:(i + taille_fenetre)])\n",
    "        y.append(target[i + taille_fenetre + horizon - 1])\n",
    "      return np.array(x), np.array(y)\n",
    "\n",
    "x_test, y_test = creer_sequences(df_test_features, df_test_target, taille_fenetre, horizon)\n",
    "batch_size = 32\n",
    "\n",
    "model = MyModelTCNNotHybrid(taille_fenetre, len(FEATURES))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae', tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "model(tf.random.uniform((batch_size, taille_fenetre, len(FEATURES))))\n",
    "print(\"model builded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 123 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 3s 8ms/step - loss: 5.3055 - mse: 5.2925 - mape: 102.4049 - mae: 1.7472 - root_mean_squared_error: 2.3005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.305510997772217,\n",
       " 5.292530536651611,\n",
       " 102.4049072265625,\n",
       " 1.7472323179244995,\n",
       " 2.3005499839782715]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"model_trained/{ville}/checkpoint_tcn_A10_{ville}_amplitude_without_topo_{horizon}h.weights.h5\")\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Persistance(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Persistance Layer\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Persistance, self).__init__(trainable=False)\n",
    "\n",
    "    # def build(self, input_shape):\n",
    "    #     pass\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ville = 'ajaccio'\n",
    "taille_fenetre = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 4ms/step - loss: 0.3324 - mse: 0.3324 - mape: 25.4106 - mae: 0.4217 - root_mean_squared_error: 0.5765\n",
      "302/302 [==============================] - 2s 5ms/step - loss: 1.2995 - mse: 1.2995 - mape: 51.6732 - mae: 0.8593 - root_mean_squared_error: 1.1400\n",
      "302/302 [==============================] - 2s 5ms/step - loss: 2.4955 - mse: 2.4955 - mape: 68.4602 - mae: 1.1819 - root_mean_squared_error: 1.5797\n",
      "301/301 [==============================] - 2s 5ms/step - loss: 4.1680 - mse: 4.1680 - mape: 78.7980 - mae: 1.4741 - root_mean_squared_error: 2.0416\n",
      "301/301 [==============================] - 2s 5ms/step - loss: 6.3539 - mse: 6.3539 - mape: 89.1965 - mae: 1.7137 - root_mean_squared_error: 2.5207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.57654869556427,\n",
       " 1.1399524211883545,\n",
       " 1.579726219177246,\n",
       " 2.0415661334991455,\n",
       " 2.5206854343414307]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = []\n",
    "for horizon in [1,3,6,12,24]:\n",
    "  TARGET = 'A10'\n",
    "\n",
    "  df_test = pd.read_csv(f\"data/test_{ville}.csv\")\n",
    "  df_test_target = df_test[[TARGET]].to_numpy()\n",
    "  df_test_features = df_test[[TARGET]].to_numpy()\n",
    "\n",
    "  model = tf.keras.Sequential(\n",
    "              [\n",
    "                  Persistance(),\n",
    "              ]\n",
    "          )\n",
    "  model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae', tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  def creer_sequences(features, target, taille_fenetre, horizon):\n",
    "        x, y = [], []\n",
    "        for i in range(len(features) - taille_fenetre - horizon + 1):\n",
    "          x.append(features[i:(i + taille_fenetre)])\n",
    "          y.append(target[i + taille_fenetre + horizon - 1])\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "  x_test, y_test = creer_sequences(df_test_features, df_test_target, taille_fenetre, horizon)\n",
    "\n",
    "  rmse.append(model.evaluate(x_test, y_test)[4])\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
